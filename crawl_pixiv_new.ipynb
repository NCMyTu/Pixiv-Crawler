{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e453175-b0bd-4c1d-a5c2-b95dd77ffa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import random\n",
    "import requests\n",
    "import pyautogui\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "HEADERS = {\n",
    "    \"Referer\": \"https://www.pixiv.net/\",\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4b3d6-7ace-4e4e-8216-f4b014528d78",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64576f6c-784d-47e3-a3a3-2c40732a53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down(driver, n_times):\n",
    "    \"\"\"\n",
    "    Scrolls down the current page using the Selenium WebDriver.\n",
    "\n",
    "    Parameters:\n",
    "        driver : selenium.webdriver\n",
    "            Selenium WebDriver instance currently viewing the page.\n",
    "        n_times : int\n",
    "            The number of times to scroll down (each scroll is 1000 pixels).\n",
    "    \"\"\"\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    for _ in range(n_times):\n",
    "        actions.scroll_by_amount(0, 5000).perform()  # effectively scroll down to the end of the page, \n",
    "        time.sleep(0.3)\n",
    "\n",
    "def login(driver, email, password):\n",
    "    \"\"\"\n",
    "    Logs in to Pixiv using the provided credentials.\n",
    "\n",
    "    Parameters:\n",
    "        driver : selenium.webdriver\n",
    "            Selenium WebDriver instance currently on the Pixiv login page.\n",
    "        email : string\n",
    "            The email address or Pixiv ID used to log in.\n",
    "        password : string\n",
    "            The password corresponding to the given email.\n",
    "    \"\"\"\n",
    "    email_input = driver.find_element(By.CSS_SELECTOR, \"input[placeholder='E-mail address or pixiv ID']\")\n",
    "    email_input.send_keys(email)\n",
    "    time.sleep(1)\n",
    "    password_input = driver.find_element(By.CSS_SELECTOR, \"input[placeholder='Password']\")\n",
    "    password_input.send_keys(password)\n",
    "    time.sleep(1)\n",
    "    password_input.send_keys(Keys.ENTER)\n",
    "\n",
    "def read_account_info(path):\n",
    "    \"\"\"\n",
    "    Reads account login information from a file.\n",
    "\n",
    "    Parameters:\n",
    "        path : string\n",
    "            The file path to a text file containing login information in key=value format.\n",
    "\n",
    "    Returns:\n",
    "        dict\n",
    "            A dictionary where each key is the left-hand side of a line split by \"=\",\n",
    "            and the corresponding value is the right-hand side (RHS)\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    \n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            temp = line.split(\"=\")\n",
    "            key = temp[0].strip()\n",
    "            value = temp[1].strip()\n",
    "\n",
    "            info[key] = value\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5e68d-7dc5-430c-9afa-6504df7ce491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artwork_ids(driver):\n",
    "    \"\"\"\n",
    "    Extracts artwork IDs from the current Pixiv page using the Selenium WebDriver.\n",
    "\n",
    "    Parameters:\n",
    "        driver : selenium.webdriver\n",
    "            Selenium WebDriver instance currently pointing to a Pixiv page with artworks.\n",
    "\n",
    "    Returns:\n",
    "        list (string)\n",
    "            A list of artwork IDs extracted from the page.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "\n",
    "    artworks = driver.find_elements(By.XPATH, \"//a[contains(@href, '/en/artworks/')]\")\n",
    "    \n",
    "    for artwork in artworks:\n",
    "        id = artwork.get_attribute(\"data-gtm-value\")\n",
    "        if id is not None:\n",
    "            ids.append(int(id))\n",
    "\n",
    "    return ids\n",
    "    \n",
    "def get_img_urls_from_artwork_id(driver, artwork_id, has_gui=False):\n",
    "    \"\"\"\n",
    "    Retrieves all image URLs from a Pixiv artwork page given its artwork ID.\n",
    "\n",
    "    Parameters:\n",
    "        driver : selenium.webdriver\n",
    "            Selenium WebDriver instance used to navigate and scrape the page.\n",
    "        artwork_id : int or str\n",
    "            The ID of the artwork to retrieve image URLs from.\n",
    "        has_gui : bool, default=False\n",
    "            Not implemented, indicates if the driver is running with a GUI.\n",
    "\n",
    "    Returns:\n",
    "        tuple (bool, list)\n",
    "            Bool indicates images found (True) or animated/ugoira (False), and list contains the URLs of the images.\n",
    "    \"\"\"\n",
    "    artwork_url = f\"https://www.pixiv.net/en/artworks/{artwork_id}\"\n",
    "    img_urls = []\n",
    "    \n",
    "    # show_all_class = \"sc-e1dc2ae6-1 fUQgzA\"\n",
    "    # reading_works_class = \"sc-e1dc2ae6-1 fUQgzA\" #\"sc-13c1e204-0 ixmPpS\"\n",
    "    img_class = \"sc-e1dc2ae6-1 fUQgzA\"\n",
    "    has_multiple_pages = True\n",
    "\n",
    "    driver.get(artwork_url)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # find animated/ugoira. we don't download this\n",
    "    try:\n",
    "        canvas = driver.find_element(By.TAG_NAME, \"canvas\")\n",
    "        return False, []\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    # set correct <img> class\n",
    "    try:\n",
    "        div = driver.find_element(By.XPATH, '//div[@class=\"sc-9222a8f6-2 kufPoS\"]')\n",
    "        # if div.text == \"Reading works\":\n",
    "        #     img_class = reading_works_class\n",
    "        # elif div.text == \"Show all\":\n",
    "        #     img_class = show_all_class\n",
    "    except NoSuchElementException:\n",
    "        # img_class = show_all_class\n",
    "        has_multiple_pages = False\n",
    "    \n",
    "    # print(f\"img_class: {img_class}\")\n",
    "    \n",
    "    # find number of pages\n",
    "    if has_multiple_pages:\n",
    "        n_pages_div = driver.find_elements(By.XPATH, '//div[@class=\"sc-b5e6ab10-0 krtyqW\"]')[0]\n",
    "        span = n_pages_div.find_element(By.TAG_NAME, 'span')\n",
    "        n_pages = int(span.text.strip().split(\"/\")[-1])\n",
    "    else:\n",
    "        n_pages = 1\n",
    "    \n",
    "    # print(f\"n_pages: {n_pages}\")\n",
    "\n",
    "    # get image base URL\n",
    "    img_element = driver.find_element(By.XPATH, f'//img[(@class=\"{img_class}\")]')\n",
    "    base_img_url = img_element.get_attribute(\"src\").split(\"_\")[0]\n",
    "    \n",
    "    for i in range(n_pages):\n",
    "        img_url = base_img_url + f\"_p{i}_master1200.jpg\"\n",
    "        img_urls.append(img_url)\n",
    "\n",
    "    return True, img_urls\n",
    "\n",
    "def get_img_and_pg_num(img_url):\n",
    "    \"\"\"\n",
    "    Extracts the artwork ID and page number from a Pixiv image URL.\n",
    "\n",
    "    Parameters:\n",
    "        img_url : string\n",
    "            The direct URL of the Pixiv image.\n",
    "\n",
    "    Returns:\n",
    "        tuple (int, int)\n",
    "            Artwork's ID and page number integers extracted from the URL.\n",
    "    \"\"\"\n",
    "    # image's url is in format:\n",
    "    # https://i.pximg.net/img-master/img/{yyyy}/{mm}/{dd}/{hh}/{mm}/{ss}/{artwork_id}_p{page_number}_master1200.jpg\n",
    "\n",
    "    img_info = img_url.split(\"/\")[-1]\n",
    "    img_info = img_info.split(\"_\")\n",
    "\n",
    "    artwork_id = int(img_info[0])\n",
    "    page_number = int(img_info[1][1:])\n",
    "    \n",
    "    return artwork_id, page_number\n",
    "\n",
    "def download_img(save_path, url, timeout=10):\n",
    "    \"\"\"\n",
    "    Downloads an image from a given URL and saves it to the specified path.\n",
    "\n",
    "    Parameters:\n",
    "        save_path : string\n",
    "            The file path where the image will be saved.\n",
    "        url : string\n",
    "            The URL of the image.\n",
    "        timeout : int, default=10\n",
    "            The maximum seconds to wait for a response.\n",
    "\n",
    "    Returns:\n",
    "        bool\n",
    "            True if the download is successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=timeout)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "            \n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2485f9-1085-45ea-806e-df32b224abe7",
   "metadata": {},
   "source": [
    "# Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dcfad-509d-490b-92fa-9b84b65f0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:/Users/PC MY TU/Desktop/temp_artworks\"\n",
    "\n",
    "account_info = read_account_info(\"account.txt\")\n",
    "email = account_info[\"email\"]\n",
    "password = account_info[\"password\"]\n",
    "nickname = account_info[\"nickname\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe8b03-a896-4242-b864-e53dd95e2ace",
   "metadata": {},
   "source": [
    "### Collect image URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df202c5d-1291-407b-af2b-6d2c21f501d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_id = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2585520-c914-42cd-a066-0024a30a8e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "\n",
    "# construct artist page\n",
    "artist_page = \"https://www.pixiv.net/en/users/artist_id/artworks/?p=current_page\"\n",
    "artist_page = artist_page.replace(\"artist_id\", str(artist_id))\n",
    "current_artist_page = artist_page.replace(\"current_page\", str(current_page))\n",
    "\n",
    "artwork_ids = []\n",
    "\n",
    "# set up Chrome WebDriver\n",
    "driver = uc.Chrome(use_subprocess=False)\n",
    "driver.maximize_window()\n",
    "\n",
    "login_page = \"https://accounts.pixiv.net/login\"\n",
    "driver.get(login_page)\n",
    "\n",
    "# log in\n",
    "print(\"Log in ... START\")\n",
    "# find email and password field\n",
    "login(driver, email, password)\n",
    "print(\"Log in ... DONE\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# find all artwork's ids\n",
    "print(\"Find all artwork's ids ... START\")\n",
    "has_next_page = True\n",
    "\n",
    "while has_next_page:\n",
    "    print(f\"Page: {current_page}\")\n",
    "    \n",
    "    driver.get(current_artist_page)\n",
    "    time.sleep(1)\n",
    "    scroll_down(driver, n_times=10)\n",
    "    \n",
    "    current_page_artwork_ids = get_artwork_ids(driver)\n",
    "\n",
    "    print(f\"Found {len(current_page_artwork_ids)} artworks: {current_page_artwork_ids}\")\n",
    "\n",
    "    artwork_ids.extend(current_page_artwork_ids)\n",
    "\n",
    "    # check if next page exists\n",
    "    # find previous and next button\n",
    "    btns = driver.find_elements(By.XPATH, '//a[contains(@class, \"sc-ddbdb82a-2 jnCvtc sc-ddbdb82a-1\")]')\n",
    "    hidden_attr = btns[-1].get_attribute(\"hidden\")\n",
    "    # True if no hidden attribute (next page is available)\n",
    "    has_next_page = (hidden_attr is None)\n",
    "\n",
    "    current_page += 1\n",
    "    current_artist_page = artist_page.replace(\"current_page\", str(current_page))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "print(\"Find all artwork's ids ... DONE\\nCollecting image URLs\")\n",
    "\n",
    "# collect image urls\n",
    "animated_artwork_ids = []\n",
    "img_urls = []\n",
    "\n",
    "for artwork_id in artwork_ids:\n",
    "    is_image, artwork_img_urls = get_img_urls_from_artwork_id(driver, artwork_id)\n",
    "\n",
    "    if is_image:\n",
    "        img_urls.extend(artwork_img_urls)\n",
    "    else:\n",
    "        animated_artwork_ids.append(artwork_id)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# print crawled information\n",
    "print(f\"Found a total of {len(artwork_ids)} artworks, which includes:\")\n",
    "\n",
    "print(f\"\\t{len(animated_artwork_ids)} animated/uroiga artworks:\")\n",
    "if len(animated_artwork_ids) > 0:\n",
    "    n_ids_per_row = 5\n",
    "    for i in range(0, len(animated_artwork_ids), n_ids_per_row):\n",
    "        for j in range(i, min(i + n_ids_per_row, len(animated_artwork_ids))):\n",
    "            row = animated_artwork_ids[i:i + n_ids_per_row]\n",
    "            row_str = \", \".join(str(_id) for _id in row)\n",
    "        print(f\"\\t\\t{row_str}\")\n",
    "\n",
    "print(f\"\\t{len(img_urls)} image URLs:\")\n",
    "for url in img_urls:\n",
    "    print(\"\\t\", \"\\t\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772304c2-d5b5-4e13-8de3-d0b8eb10dd9d",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca345495-9698-403e-8ff7-a0ff62f878c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_download_urls = []\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for i, url in enumerate(img_urls):\n",
    "    artwork_id, page_number = get_img_and_pg_num(url)\n",
    "    file_name = f\"{artwork_id}_p{page_number}.jpg\"\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "    print(f\"[{i+1}/{len(img_urls)}], downloading {file_name}\\t\\t\", end=\"\")\n",
    "\n",
    "    is_success = download_img(file_path, url, timeout=10)\n",
    "    \n",
    "    if is_success:\n",
    "        print(\"ok\")\n",
    "    else:\n",
    "        print(\"FAILED\")\n",
    "        failed_download_urls.append(url)\n",
    "\n",
    "    time.sleep(random.choice([0, 0.5]))\n",
    "\n",
    "print(\"DOWNLOADING DONE\")\n",
    "\n",
    "if failed_download_urls:\n",
    "    print(\"\\nFAILED:\\n\")\n",
    "\n",
    "    for url in failed_download_urls:\n",
    "        print(url)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
